{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AsymmetricCroCo3DStereo(\n",
       "  (patch_embed): PatchEmbedDust3R(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (mask_generator): RandomMask()\n",
       "  (rope): cuRoPE2D()\n",
       "  (enc_blocks): ModuleList(\n",
       "    (0-23): 24 x Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): cuRoPE2D()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (enc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (decoder_embed): Linear(in_features=1024, out_features=768, bias=True)\n",
       "  (dec_blocks): ModuleList(\n",
       "    (0-11): 12 x DecoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): cuRoPE2D()\n",
       "      )\n",
       "      (cross_attn): CrossAttention(\n",
       "        (projq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (projk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (projv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): cuRoPE2D()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm_y): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dec_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (dec_blocks2): ModuleList(\n",
       "    (0-11): 12 x DecoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): cuRoPE2D()\n",
       "      )\n",
       "      (cross_attn): CrossAttention(\n",
       "        (projq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (projk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (projv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): cuRoPE2D()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm_y): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (downstream_head1): PixelwiseTaskWithDPT(\n",
       "    (dpt): DPTOutputAdapter_fix(\n",
       "      (scratch): Module(\n",
       "        (layer1_rn): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer2_rn): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer3_rn): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer4_rn): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer_rn): ModuleList(\n",
       "          (0): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (refinenet1): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet2): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet3): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet4): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Interpolate()\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act_postprocess): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ConvTranspose2d(96, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ConvTranspose2d(192, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downstream_head2): PixelwiseTaskWithDPT(\n",
       "    (dpt): DPTOutputAdapter_fix(\n",
       "      (scratch): Module(\n",
       "        (layer1_rn): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer2_rn): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer3_rn): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer4_rn): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer_rn): ModuleList(\n",
       "          (0): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (refinenet1): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet2): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet3): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet4): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Interpolate()\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act_postprocess): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ConvTranspose2d(96, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ConvTranspose2d(192, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dust3r.inference import inference, load_model\n",
    "\n",
    "model_path = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "device = 'cpu'\n",
    "\n",
    "model = load_model(model_path, device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ck['args'].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.arange(0, 10, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
